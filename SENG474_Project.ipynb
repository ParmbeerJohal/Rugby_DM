{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Outcome of the 2019 Rugby World Cup\n",
    "\n",
    "On November 2nd, the 2019 Rugby World Cup came to a conclusion in Yokohama, Japan. Twenty teams, six weeks, one champion.\n",
    "\n",
    "---\n",
    "\n",
    "Our goal is to build a model that can accurately predict the winner and score for each Rugby World Cup match-up. The overall outline is as follows:\n",
    "\n",
    "1. Data Collection\n",
    "2. Data Preprocessing and Visualization\n",
    "3. Data Mining and Predictions\n",
    "\n",
    "To evaluate our model, we will be comparing our predictions to the actual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4a2b882c0c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "In order to train our model, we shall require a dataset containing historical statistics from previously held rugby matches.\n",
    "\n",
    "Fortunately, [ESPN Scrum](espnscrum.com) provides data on players, teams, and matches going back to 1896.\n",
    "\n",
    "### Building ```rugby_pg.db```\n",
    "* Using a scrapy spider built by peloyeje (found [here](https://github.com/peloyeje/map536-rugby-data-scraper)), it was possible to collect a meaningful sample of matches and results, along with player stats for each match to work with.\n",
    "\n",
    "* After scraping player, team, and match stats from ESPN Scrum the data was inserted into a SQLite database.\n",
    "    * Although SQLite format is perfectly fine to work with, we have more experience with PostgreSQL. \n",
    "    * To make things easier for ourselves, we converted the SQLite into a PostgreSQL database.\n",
    "  \n",
    "### Building ```rankings.csv```\n",
    "* The World Rugby rankings were gathered from [World Rugby's website](https://www.world.rugby/rankings/mru?lang=en) using Beautiful Soup.\n",
    "\n",
    "* We were able to gather data points containing ```team_name```, ```abbreviation```, ```num_matches```, ```pts```, ```pos```, ```prev_pts```, ```prev_pos```, ```data```.\n",
    "\n",
    "    * Each data point represents a single team's data from the given date.\n",
    "\n",
    "    * World Rugby began recording this data on November 2003, so unfortunately there are many years of competition that are not represented in the data set.\n",
    "    \n",
    "* The scraping process was done outside of a Jupyter Notebook, due to the heavy memory consumption required to build this large data set\n",
    "\n",
    "    * Instead, by creating ```csv_writer.py``` and running this python program on a machine with high-spec hardware, the data set ```rankings.csv``` was built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''This is the code from csv_writer.py --- it has been commented out to prevent the Jupyter Notebook from building the data set'''\n",
    "\n",
    "\n",
    "# import json\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# from datetime import timedelta, date\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import csv\n",
    "\n",
    "# def daterange(start_date, end_date):\n",
    "#     for n in range(int ((end_date - start_date).days)):\n",
    "#         yield start_date + timedelta(n)\n",
    "\n",
    "# start_date = date(2003, 10, 13)\n",
    "# end_date = date(2019, 11, 15)\n",
    "\n",
    "# csv_data = [['team_name', 'abbreviation', 'num_matches', 'pts', 'pos', 'prev_pts', 'prev_pos', 'date']]\n",
    "\n",
    "# for single_date in daterange(start_date, end_date):\n",
    "#     date = single_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#     ranking_url = \"cmsapi.pulselive.com/rugby/rankings/mru?date=%s&client=pulse\" % date\n",
    "#     r  = requests.get(\"http://\" + ranking_url)\n",
    "\n",
    "#     soup = BeautifulSoup(r.text)\n",
    "\n",
    "#     data = json.loads(soup.body.p.text)\n",
    "#     for entry in data['entries']:\n",
    "#         csv_data.append(\n",
    "#             [entry['team']['name'], entry['team']['abbreviation'], \n",
    "#              entry['matches'], entry['pts'], entry['pos'], entry['previousPts'], \n",
    "#              entry['previousPos'], date]\n",
    "#         )\n",
    "\n",
    "# with open('rankings.csv', 'w') as csv_file:\n",
    "#     writer = csv.writer(csv_file)\n",
    "#     writer.writerows(csv_data)\n",
    "# csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization -\n",
    "\n",
    "### Preprocessing ```rankings.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ranking_data/rankings.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Python library ```matplotlib```, we can create several graphs from the ```rankings.csv``` dataset.\n",
    "\n",
    "We will mainly explore the dynamics between the top ranking teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "for abbr in data.loc[data.pos < 4].abbreviation.unique():\n",
    "    abbr_pts = data.loc[data.abbreviation == abbr].values[:,[3]]\n",
    "    if abbr == 'NZL':\n",
    "        plt.plot(abbr_pts, label = abbr, color = 'black')\n",
    "    elif abbr == 'ENG':\n",
    "        plt.plot(abbr_pts, label = abbr, color = 'red')\n",
    "    elif abbr == 'AUS':\n",
    "        plt.plot(abbr_pts, label = abbr, color = 'gold')\n",
    "    elif abbr == 'RSA':\n",
    "        plt.plot(abbr_pts, label = abbr, color = 'darkgreen')\n",
    "    elif abbr == 'IRE':\n",
    "        plt.plot(abbr_pts, label = abbr, color = 'lime')\n",
    "    elif abbr == 'ARG':\n",
    "        plt.plot(abbr_pts, label = abbr, color = 'lightskyblue')\n",
    "    elif abbr == 'WAL':\n",
    "        plt.plot(abbr_pts, label = abbr, color = 'magenta')\n",
    "    else:\n",
    "        plt.plot(abbr_pts, label = abbr)\n",
    "    \n",
    "plt.title(\"Points of Top 3 Ranked Countries Since 2003\")\n",
    "plt.xlabel(\"Entry #\")\n",
    "plt.ylabel(\"Points\")\n",
    "ax = plt.gca()\n",
    "plt.legend(bbox_to_anchor=(1, 1), bbox_transform=ax.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the graph above presents a ton of valuable information, the data is very noisy and does not allow for easy understanding of the situation that is being represented.\n",
    "\n",
    "- To improve understanding, we will now calculate the average points per year, rather than the points on each date.\n",
    "\n",
    "The following table was created directly from ``rankings.csv`` by first inserting the file into a postgres server and then using the SQL command:<br />\n",
    "~~~~sql\n",
    "    SELECT team_name, pos, extract(year FROM date) AS year, AVG(points)\n",
    "    FROM rankings\n",
    "    GROUP BY team_name, pos, year\n",
    "    HAVING pos < 4\n",
    "    ORDER BY year;\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d6bb02202988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ranking_data/avg_pts_perteam_perpos_peryr.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"ranking_data/avg_pts_perteam_perpos_peryr.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "for team in data.loc[data.pos < 4].team_name.unique():\n",
    "    points = data.loc[data.team_name == team].values[:,[3]]\n",
    "    date = data.loc[data.team_name == team].values[:,[2]]\n",
    "    if team == 'New Zealand':\n",
    "        plt.plot(date, points, label = team, color = 'black')\n",
    "    elif team == 'England':\n",
    "        plt.plot(date, points, label = team, color = 'red')\n",
    "    elif team == 'Australia':\n",
    "        plt.plot(date, points, label = team, color = 'gold')\n",
    "    elif team == 'South Africa':\n",
    "        plt.plot(date, points, label = team, color = 'darkgreen')\n",
    "    elif team == 'Ireland':\n",
    "        plt.plot(date, points, label = team, color = 'lime')\n",
    "    elif team == 'Argentina':\n",
    "        plt.plot(date, points, label = team, color = 'lightskyblue')\n",
    "    elif team == 'Wales':\n",
    "        plt.plot(date, points, label = team, color = 'magenta')\n",
    "    else:\n",
    "        plt.plot(date, points, label = team)\n",
    "\n",
    "    \n",
    "plt.title(\"Average Points of Top 3 Ranked Countries per year Since 2003\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"Points\")\n",
    "ax = plt.gca()\n",
    "plt.legend(bbox_to_anchor=(1, 1), bbox_transform=ax.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, we notice that there are only eight teams that have ever been ranked in the top 3. We verified this by querying the ``rankings.csv`` dataset with:\n",
    "~~~~sql\n",
    "SELECT DISTNCT team_name\n",
    "FROM rankings\n",
    "WHERE pos < 4;\n",
    "~~~~\n",
    "\n",
    "Next, we looked at the average ranking of these eight teams from 2003 to 2019, in order to get a better sense of which teams are consistently ranked at the top. The query follows:\n",
    "~~~~sql\n",
    "SELECT team_name, AVG(pos) AS average_position\n",
    "FROM rankings\n",
    "GROUP BY team_name\n",
    "HAVING team_name = 'New Zealand'\n",
    "OR team_name = 'Australia'\n",
    "OR team_name = 'England'\n",
    "OR team_name = 'South Africa'\n",
    "OR team_name = 'France'\n",
    "OR team_name = 'Ireland'\n",
    "OR team_name = 'Argentina'\n",
    "OR team_name = 'Wales'\n",
    "ORDER BY average_position;\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ranking_data/avg_pos.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also looked at the worst ranking of these eight teams during the time period of 2003 to 2019. \n",
    "\n",
    "Again, the query follows:\n",
    "~~~~sql\n",
    "SELECT team_name, MAX(pos) AS worst_position\n",
    "FROM rankings\n",
    "GROUP BY team_name\n",
    "HAVING team_name = 'New Zealand'\n",
    "OR team_name = 'Australia'\n",
    "OR team_name = 'England'\n",
    "OR team_name = 'South Africa'\n",
    "OR team_name = 'France'\n",
    "OR team_name = 'Ireland'\n",
    "OR team_name = 'Argentina'\n",
    "OR team_name = 'Wales'\n",
    "ORDER BY worst_position;\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ranking_data/worst_pos.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing ```rugby_pg.db```\n",
    "\n",
    "Using pg_restore on ```rugby_pg.db``` we created a PostgreSQL database containing all the historical data we previously scraped from ESPN Scrum. We interacted with the database by using the Python library, ```pscopg2```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"rugby\", user=\"postgres\", password=\"postgres\")\n",
    "cur = conn.cursor(cursor_factory = psycopg2.extras.DictCursor)\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "        SELECT *\n",
    "        FROM\n",
    "          (SELECT id, date, match_type\n",
    "           FROM matchs) match_date\n",
    "        JOIN\n",
    "          (SELECT *\n",
    "           FROM matchstats\n",
    "           JOIN teams ON teams.id = matchstats.team_id) match_team ON match_date.id = match_team.match_id \n",
    "        WHERE date > '2003-10-12'::date;\n",
    "    \"\"\")\n",
    "data = cur.fetchall()\n",
    "\n",
    "match_data = pd.DataFrame([i.copy() for i in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running further queries on the tables we have gathered from ESPN Scrum, we were able to calculate each team's total win percentage over all games they have previously played. \n",
    "\n",
    "The code to obtain this table is given in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "        SELECT x.name, x.num_matches, y.total_wins, (y.total_wins::NUMERIC / x.num_matches::NUMERIC * 100.0::NUMERIC)::NUMERIC AS win_percentage\n",
    "        FROM (SELECT teams.name, COUNT(*) AS num_matches\n",
    "              FROM teams JOIN matchstats ON teams.id = matchstats.team_id\n",
    "              GROUP BY teams.name) x\n",
    "              JOIN (SELECT a.name, (a.home_wins + b.away_wins) AS total_wins\n",
    "                    FROM (SELECT teams.name, COUNT(matchs.won) AS home_wins\n",
    "                          FROM teams\n",
    "                          JOIN matchs ON teams.id = matchs.home_team_id\n",
    "                          GROUP BY teams.name, matchs.won\n",
    "                          HAVING won = 1) a\n",
    "                    JOIN (SELECT teams.name, COUNT(matchs.won) AS away_wins\n",
    "                          FROM teams JOIN matchs ON teams.id = matchs.away_team_id\n",
    "                          GROUP BY teams.name, matchs.won\n",
    "                          HAVING won = 2) b\n",
    "              ON a.name = b.name) y\n",
    "        ON x.name = y.name\n",
    "        ORDER BY win_percentage DESC;\n",
    "    \"\"\")\n",
    "data = cur.fetchall()\n",
    "win_percentage_data = pd.DataFrame([i.copy() for i in data])\n",
    "win_percentage_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we notice that there needs to be some cleaning of this dataset as it currently contains teams that have only played a handful of matches. \n",
    "- These win percentages can be quite misleading, as some teams have not played a meaningful amount of games.\n",
    "    - To remove the misleading statistics, we set a new criteria of **having at least 50 games played**.\n",
    "    - After cleaning the data (using the condition that the minimum number of games played be 50) we obtain the processed table below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "        SELECT x.name, x.num_matches, y.total_wins, (y.total_wins::NUMERIC / x.num_matches::NUMERIC * 100.0::NUMERIC)::NUMERIC AS win_percentage\n",
    "        FROM (SELECT teams.name, COUNT(*) AS num_matches\n",
    "              FROM teams JOIN matchstats ON teams.id = matchstats.team_id\n",
    "              GROUP BY teams.name) x\n",
    "        JOIN (SELECT a.name, (a.home_wins + b.away_wins) AS total_wins\n",
    "                    FROM (SELECT teams.name, COUNT(matchs.won) AS home_wins\n",
    "                          FROM teams\n",
    "                          JOIN matchs ON teams.id = matchs.home_team_id\n",
    "                          GROUP BY teams.name, matchs.won\n",
    "                          HAVING won = 1) a\n",
    "                    JOIN (SELECT teams.name, COUNT(matchs.won) AS away_wins\n",
    "                          FROM teams JOIN matchs ON teams.id = matchs.away_team_id\n",
    "                          GROUP BY teams.name, matchs.won\n",
    "                          HAVING won = 2) b\n",
    "              ON a.name = b.name) y\n",
    "        ON x.name = y.name\n",
    "        WHERE x.num_matches > 49\n",
    "        ORDER BY win_percentage DESC;\n",
    "    \"\"\")\n",
    "data = cur.fetchall()\n",
    "\n",
    "win_percentage_data = pd.DataFrame([i.copy() for i in data])\n",
    "\n",
    "print(win_percentage_data)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "\n",
    "win_percentage_data.win_percentage = win_percentage_data.win_percentage.astype(float)\n",
    "top_win_percentage_data = win_percentage_data.nlargest(10, 'win_percentage')\n",
    "\n",
    "plt.bar(top_win_percentage_data.name, top_win_percentage_data.win_percentage, color = ['black', 'red', 'darkgreen', 'darkred', 'gold', 'blue', 'lightcoral', 'olive', 'green', 'darkblue'])\n",
    "plt.title(\"Top 10 Win Percentages of Teams (Minimum 50 Games Played)\")\n",
    "plt.ylabel(\"Win Percentage\")\n",
    "plt.xlabel(\"Team Name\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By querying only the teams with a minimum 50 games played, we have been able to remove many teams with unmeaningful records, but the resulting statistics are still quite misleading. \n",
    "- The main issue being, tier 2 teams such as Kenya and Hong Kong do not play against the same caliber opposition when compared to tier 1 teams like New Zealand and England.\n",
    "    - To remove these misleading statistics, we set a raise our criteria to **having at least 250 games played**.\n",
    "    - After cleaning the data (using the condition that the minimum number of games played be 250) we obtain the processed table below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "        SELECT x.name, x.num_matches, y.total_wins, (y.total_wins::NUMERIC / x.num_matches::NUMERIC * 100.0::NUMERIC)::NUMERIC AS win_percentage\n",
    "        FROM (SELECT teams.name, COUNT(*) AS num_matches\n",
    "              FROM teams JOIN matchstats ON teams.id = matchstats.team_id\n",
    "              GROUP BY teams.name) x\n",
    "        JOIN (SELECT a.name, (a.home_wins + b.away_wins) AS total_wins\n",
    "                    FROM (SELECT teams.name, COUNT(matchs.won) AS home_wins\n",
    "                          FROM teams\n",
    "                          JOIN matchs ON teams.id = matchs.home_team_id\n",
    "                          GROUP BY teams.name, matchs.won\n",
    "                          HAVING won = 1) a\n",
    "                    JOIN (SELECT teams.name, COUNT(matchs.won) AS away_wins\n",
    "                          FROM teams JOIN matchs ON teams.id = matchs.away_team_id\n",
    "                          GROUP BY teams.name, matchs.won\n",
    "                          HAVING won = 2) b\n",
    "              ON a.name = b.name) y\n",
    "        ON x.name = y.name\n",
    "        WHERE x.num_matches > 249\n",
    "        ORDER BY win_percentage DESC;\n",
    "    \"\"\")\n",
    "data = cur.fetchall()\n",
    "\n",
    "win_percentage_data = pd.DataFrame([i.copy() for i in data])\n",
    "\n",
    "print(win_percentage_data)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "\n",
    "win_percentage_data.win_percentage = win_percentage_data.win_percentage.astype(float)\n",
    "top_win_percentage_data = win_percentage_data.nlargest(10, 'win_percentage')\n",
    "\n",
    "plt.bar(top_win_percentage_data.name, top_win_percentage_data.win_percentage, color = ['black', 'red', 'darkgreen', 'gold', 'blue', 'lightcoral', 'green', 'lightskyblue', 'magenta', 'darkblue'])\n",
    "plt.title(\"Top 10 Win Percentages of Teams (Minimum 250 Games Played)\")\n",
    "plt.ylabel(\"Win Percentage\")\n",
    "plt.xlabel(\"Team Name\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above displays teams that regularly compete against one another. This allows for a more meaningful comparison, as we are not looking at teams who likely never face against echother."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining ```rankings.csv``` and ```rugby_pg.db```\n",
    "\n",
    "By joining the ```rankings.csv``` data with our match statistics, we can observe how rankings correlate to match outcomes.\n",
    "\n",
    "- Due to World Rugby rankings first being recorded in 2003, our match data for this section will only cover 2003 onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''This is the code used to gather the ranking position and points for each team on the date of their match --- it has been commented out to prevent the Jupyter Notebook from building the data set'''\n",
    "\n",
    "# rankings_data = pd.read_csv(\"ranking_data/rankings.csv\")\n",
    "\n",
    "# match_data.date = match_data.date.astype(str)\n",
    "# rankings_data.date = rankings_data.date.astype(str)\n",
    "\n",
    "# ordered_pos = []\n",
    "# ordered_pts = []\n",
    "\n",
    "# for rec in match_data.itertuples():\n",
    "#     team_name = rec.name\n",
    "#     if team_name == 'United States of America':\n",
    "#         team_name = 'USA'\n",
    "#     if rankings_data.loc[(rankings_data.team_name == team_name) & (rankings_data.date == rec.date)].empty:\n",
    "#         ordered_pos.append(-1)\n",
    "#         ordered_pts.append(-1)\n",
    "#     else:\n",
    "#         ordered_pos.append(\n",
    "#             rankings_data.loc[\n",
    "#                 (rankings_data.team_name == team_name) & (rankings_data.date == rec.date)\n",
    "#             ].values[:,[4]][0][0])\n",
    "\n",
    "#         ordered_pts.append(\n",
    "#             rankings_data.loc[\n",
    "#                 (rankings_data.team_name == team_name) & (rankings_data.date == rec.date)\n",
    "#             ].values[:,[3]][0][0])\n",
    "\n",
    "# match_data['pos'] = ordered_pos\n",
    "# match_data['pts'] = ordered_pts\n",
    "\n",
    "# export_csv = match_data.to_csv(r'merged.csv', index = None, header=True)\n",
    "\n",
    "# match_rank_data = pd.read_csv('merged.csv')\n",
    "\n",
    "# opposition_name = []\n",
    "# opposition_pos = []\n",
    "# opposition_pts = []\n",
    "\n",
    "# for match in match_rank_data.itertuples():\n",
    "#     opposition_name.append(match_rank_data.loc[\n",
    "#                 (match_rank_data.match_id == match.match_id) & (match_rank_data.name != match.name)\n",
    "#             ].values[:,11][0])\n",
    "    \n",
    "#     opposition_pos.append(match_rank_data.loc[\n",
    "#                 (match_rank_data.match_id == match.match_id) & (match_rank_data.name != match.name)\n",
    "#             ].values[:,12][0])\n",
    "    \n",
    "#     opposition_pts.append(match_rank_data.loc[\n",
    "#                 (match_rank_data.match_id == match.match_id) & (match_rank_data.name != match.name)\n",
    "#             ].values[:,13][0])\n",
    "\n",
    "# match_rank_data['opp_name'] = opposition_name\n",
    "# match_rank_data['opp_pos'] = opposition_pos\n",
    "# match_rank_data['opp_pts'] = opposition_pts\n",
    "\n",
    "# export_csv = match_rank_data.to_csv(r'merged_with_oppo.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If there was no ranking entry for a given team on a certain date, the value ```-1``` was used for ```pos``` and ```pts```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "complete_match_data = pd.read_csv('merged_with_oppo.csv')\n",
    "\n",
    "complete_match_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, we shall observe how often the higher ranked team wins for each fixture. \n",
    "    - We expect a positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = complete_match_data\n",
    "\n",
    "high_win = len(data.loc[\n",
    "        (data.pos < data.opp_pos) \n",
    "        & (data.scored > data.conceded)\n",
    "        & (data.pos != -1) \n",
    "        & (data.opp_pos != -1)\n",
    "    ])\n",
    "high_total = len(data.loc[\n",
    "        (data.pos < data.opp_pos)\n",
    "        & (data.pos != -1) \n",
    "        & (data.opp_pos != -1)\n",
    "    ])\n",
    "\n",
    "high_win / high_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring further, how does this rate change when looking at the top $n$ ranked teams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "win_rate_by_rank = {}\n",
    "\n",
    "for n in range(2, 104):\n",
    "    high_win = len(data.loc[\n",
    "        (data.pos < data.opp_pos) \n",
    "        & (data.scored > data.conceded) \n",
    "        & (data.opp_pos < n + 1) \n",
    "        & (data.pos != -1) \n",
    "        & (data.opp_pos != -1)\n",
    "    ])\n",
    "    \n",
    "    high_total = len(data.loc[\n",
    "        (data.pos < data.opp_pos) \n",
    "        & (data.opp_pos < n + 1)\n",
    "        & (data.pos != -1) \n",
    "        & (data.opp_pos != -1)\n",
    "    ])\n",
    "    \n",
    "    win_rate_by_rank[n] = high_win / high_total\n",
    "    \n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.plot(list(win_rate_by_rank.keys()), list(win_rate_by_rank.values()))\n",
    "plt.title(\"Rate of Higher Ranked Team Win per Top n Ranked Teams\")\n",
    "plt.xlabel(\"Top n Ranked Teams\")\n",
    "plt.ylabel(\"Win Rate\")\n",
    "# plt.gca().invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, we can observe that games between high ranking teams (teams who rank > 10) are more competitive than those of lesser ranked teams. \n",
    "\n",
    "We can also see that as we near the top ranked team, the win rate spikes up. This is likely due to New Zealand's dominance over the years, which can be supported by the overall win rates we looked at earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats = {}\n",
    "\n",
    "data.date = pd.to_datetime(data['date'])\n",
    "\n",
    "team_one = 'New Zealand'\n",
    "team_two = 'Australia'\n",
    "\n",
    "for n in range(2003, 2020):\n",
    "    win = len(data.loc[\n",
    "        (data.name == team_one)\n",
    "        & (data.opp_name == team_two)\n",
    "        & (data.scored > data.conceded)\n",
    "        & (data.date.dt.year == n)\n",
    "    ])\n",
    "\n",
    "    total = len(data.loc[\n",
    "        (data.name == team_one)\n",
    "        & (data.opp_name == team_two)\n",
    "        & (data.date.dt.year == n)\n",
    "    ])\n",
    "\n",
    "    if total == 0:\n",
    "        stats[n] = np.nan\n",
    "    else:\n",
    "        stats[n] = win / total\n",
    "    \n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.plot(list(stats.keys()), list(stats.values()))\n",
    "plt.title(\"Rate of New Zealand Victory vs Australia per Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"New Zealands's Win Rate\")\n",
    "# plt.gca().invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar fashion, we generalize the data to get the overall win percentage of New Zealand against the top 12 teams in the world. The 12 is chosen due to the fact that the worst position shown in the 'worst_pos.csv' file is 12th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stats = {}\n",
    "\n",
    "data.date = pd.to_datetime(data['date'])\n",
    "\n",
    "team_one = 'New Zealand'\n",
    "\n",
    "for n in range(2003, 2020):\n",
    "    win = len(data.loc[\n",
    "        (data.name == team_one)\n",
    "        & (data.opp_pos < 13)\n",
    "        & (data.scored > data.conceded)\n",
    "        & (data.date.dt.year == n)\n",
    "    ])\n",
    "\n",
    "    total = len(data.loc[\n",
    "        (data.name == team_one)\n",
    "        & (data.opp_pos < 13)\n",
    "        & (data.date.dt.year == n)\n",
    "    ])\n",
    "\n",
    "    if total == 0:\n",
    "        stats[n] = np.nan\n",
    "    else:\n",
    "        stats[n] = win / total\n",
    "    \n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.plot(list(stats.keys()), list(stats.values()))\n",
    "plt.title(\"Rate of New Zealand Victory vs Top 12 teams per Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"New Zealands's Win Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we begin to focus more towards team stats on the big stage, the World cup. \n",
    "\n",
    "There have been many teams qualifying for the world cup and battling it out in the pool stages, but only a handful of teams have progressed to the knockout stages. \n",
    "\n",
    "We have compiled a list of these teams below with their id and the number of knockout stage appearances. \n",
    "\n",
    "The data can be found [here](https://www.rugbyworldcup.com/) (Note: the time reference is from 2003 to present time, which is equivalent to 5 World Cups):\n",
    "\n",
    "   |**Id**|**teams**|**wc knockout appearances**|\n",
    "   |------|---------|---------------------------|\n",
    "   |6|Australia|5|\n",
    "   |9|France|5|\n",
    "   |8|New Zealand|5|\n",
    "   |5|South Africa|5|\n",
    "   |1|England|4|\n",
    "   |3|Ireland|4|\n",
    "   |4|Wales|4|\n",
    "   |10|Argentina|3|\n",
    "   |2|Scotland|3|\n",
    "   |14|Fiji|1|\n",
    "   |23|Japan|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining and Predictions\n",
    "\n",
    "Now that we have gathered our data and analyzed several interesting statistics, we can build our model for computation.\n",
    "\n",
    "First, we will need to query our dataset for each ``match_id`` for the 48 matches that are played at the World Cup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "\n",
    "wc_match_ids = data.loc[\n",
    "        (data.date > datetime.date(2019, 9, 19))\n",
    "        & (data.pos < 19)\n",
    "        & (data.pos != -1)\n",
    "    ].match_id.unique()\n",
    "\n",
    "wc_match_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_matches = []\n",
    "\n",
    "for match_id in wc_match_ids:\n",
    "    curr_game = data.loc[data.match_id == match_id].iloc[0]\n",
    "    wc_matches.append(curr_game)\n",
    "    \n",
    "# for match in wc_matches:\n",
    "#     print(match['name'] + \" vs. \" + match['opp_name'])\n",
    "    \n",
    "print(len(wc_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normally, each Rugby World Cup consists of 48 matches in total. \n",
    "    - Unfortunately, in 2019 three of the pool games were called off due to a dangerous typhoon. The result of these matches all were counted as ties. \n",
    "\n",
    "\n",
    "- For the rest of our project, we will be ignoring these games, as it is impossible to predict a typhoon from the data we have collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wc_match_info = {}\n",
    "    \n",
    "for match in wc_matches:\n",
    "    team_one = match['name']\n",
    "    team_two = match['opp_name']\n",
    "\n",
    "    team_one_pos = match['pos']\n",
    "    team_two_pos = match['opp_pos']\n",
    "    \n",
    "    past_match_stats = data.loc[\n",
    "                (data.name == team_one)\n",
    "            & (data.opp_name == team_two)\n",
    "            & (data.date < match['date'])\n",
    "        ]\n",
    "    \n",
    "    score_diff = past_match_stats.sum(axis = 0, skipna = True).scored - past_match_stats.sum(axis = 0, skipna = True).conceded\n",
    "\n",
    "# Use the actual resulting score difference as Y, to compare our prediction to the actual result\n",
    "    team_one_score = match['scored']\n",
    "    team_two_score = match['conceded']\n",
    "    \n",
    "    resulting_score_diff = team_one_score - team_two_score\n",
    "    \n",
    "    win_count = 0\n",
    "    draw_count = 0\n",
    "    loss_count = 0\n",
    "    \n",
    "    for past_match in past_match_stats.values:\n",
    "        if past_match[4] > past_match[5]:\n",
    "            win_count += 1\n",
    "        if past_match[4] == past_match[5]:\n",
    "            draw_count += 1\n",
    "        if past_match[4] < past_match[5]:\n",
    "            loss_count += 1\n",
    "\n",
    "    if (win_count + draw_count + loss_count) > 0:\n",
    "        win_percentage = win_count / (win_count + draw_count + loss_count)\n",
    "    else:\n",
    "        win_percentage = 0.0\n",
    "    \n",
    "    wc_match_info[match['match_id']] = [1, score_diff, win_percentage, team_one_pos, team_two_pos, resulting_score_diff]\n",
    "\n",
    "# wc_match_info contains data for each 2019 World Cup match \n",
    "# -- The format is {match_id : [dummy, score_diff, win_percentage, team_one_pos, team_two_pos, resulting_score_diff]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code builds our **testing** dataset. Each testing instance is one of the 2019 World Cup matches, and consists of the following attributes:\n",
    "\n",
    "    [dummy, score_diff, win_percentage, team_one_pos, team_two_pos, resulting_score_diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_wc_match_ids = data.loc[\n",
    "        (data.date < '2019-09-20')\n",
    "        & (\n",
    "            (data.name == 'Argentina')\n",
    "            | (data.name == 'Australia')\n",
    "            | (data.name == 'Canada')\n",
    "            | (data.name == 'England')\n",
    "            | (data.name == 'Fiji')\n",
    "            | (data.name == 'France')\n",
    "            | (data.name == 'Georgia')\n",
    "            | (data.name == 'Ireland')\n",
    "            | (data.name == 'Italy')\n",
    "            | (data.name == 'Japan')\n",
    "            | (data.name == 'Namibia')\n",
    "            | (data.name == 'New Zealand')\n",
    "            | (data.name == 'Russia')\n",
    "            | (data.name == 'Samoa')\n",
    "            | (data.name == 'Scotland')\n",
    "            | (data.name == 'South Africa')\n",
    "            | (data.name == 'Tonga')\n",
    "            | (data.name == 'Uruguay')\n",
    "            | (data.name == 'USA')\n",
    "            | (data.name == 'Wales')\n",
    "        )\n",
    "    ].match_id.unique()\n",
    "    \n",
    "pre_wc_matches = []\n",
    "\n",
    "for match_id in pre_wc_match_ids:\n",
    "    curr_game = data.loc[data.match_id == match_id].iloc[0]\n",
    "    pre_wc_matches.append(curr_game)\n",
    "    \n",
    "pre_wc_match_info = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code builds our **training** dataset. Each testing instance is one of the many matches played by a World Cup team prior to the 2019 World Cup, and consists of the following attributes:\n",
    "\n",
    "    [dummy, score_diff, win_percentage, team_one_pos, team_two_pos, resulting_score_diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_teams = [\n",
    "    'Argentina',\n",
    "    'Australia',\n",
    "    'Canada',\n",
    "    'England',\n",
    "    'Fiji',\n",
    "    'France',\n",
    "    'Georgia',\n",
    "    'Ireland',\n",
    "    'Italy',\n",
    "    'Japan',\n",
    "    'Namibia',\n",
    "    'New Zealand',\n",
    "    'Russia',\n",
    "    'Samoa',\n",
    "    'Scotland',\n",
    "    'South Africa',\n",
    "    'Tonga',\n",
    "    'Uruguay',\n",
    "    'USA',\n",
    "    'Wales'\n",
    "]\n",
    "\n",
    "for match in pre_wc_matches:\n",
    "    team_one = match['name']\n",
    "    team_two = match['opp_name']\n",
    "    \n",
    "    if (team_one not in wc_teams) or (team_two not in wc_teams):\n",
    "        continue\n",
    "\n",
    "    team_one_pos = match['pos']\n",
    "    team_two_pos = match['opp_pos']\n",
    "    \n",
    "    past_match_stats = data.loc[\n",
    "                (data.name == team_one)\n",
    "            & (data.opp_name == team_two)\n",
    "            & (data.date < match['date'])\n",
    "            & (data.date > datetime.date(2003, 1, 1))\n",
    "        ]\n",
    "    score_diff = past_match_stats.sum(axis = 0, skipna = True).scored - past_match_stats.sum(axis = 0, skipna = True).conceded\n",
    "    \n",
    "# Use the actual resulting score difference as Y, to compare our prediction to the actual result\n",
    "    team_one_score = match['scored']\n",
    "    team_two_score = match['conceded']\n",
    "    \n",
    "    resulting_score_diff = team_one_score - team_two_score\n",
    "    \n",
    "    win_count = 0\n",
    "    draw_count = 0\n",
    "    loss_count = 0\n",
    "    \n",
    "    for past_match in past_match_stats.values:\n",
    "        if past_match[4] > past_match[5]:\n",
    "            win_count += 1\n",
    "        if past_match[4] == past_match[5]:\n",
    "            draw_count += 1\n",
    "        if past_match[4] < past_match[5]:\n",
    "            loss_count += 1\n",
    "\n",
    "    if (win_count + draw_count + loss_count) > 0:\n",
    "        win_percentage = win_count / (win_count + draw_count + loss_count)\n",
    "    else:\n",
    "        win_percentage = 0.0\n",
    "    \n",
    "    pre_wc_match_info[match['match_id']] = [1, score_diff, win_percentage, team_one_pos, team_two_pos, resulting_score_diff]\n",
    "    \n",
    "#     print(match['name'] + \" vs. \" + match['opp_name'])\n",
    "#     print(pre_wc_match_info[match['match_id']])\n",
    "    \n",
    "# pre_wc_match_info contains data for all matches prior to the 2019 World Cup\n",
    "# -- The format is {match_id : [dummy, score_diff, win_percentage, team_one_pos, team_two_pos, resulting_score_diff]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now cast our dataset into numpy as an array. This allows for easy use of the many algorithms provided by ``sklearn``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data = np.asarray(list(pre_wc_match_info.values()), dtype=np.float32)\n",
    "print(training_data.shape)\n",
    "\n",
    "testing_data = np.asarray(list(wc_match_info.values()), dtype=np.float32)\n",
    "print(testing_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Predictions\n",
    "\n",
    "As we would like to predict not just the winner of each match, but the resulting score too, linear regression is an incredibly useful tool due to the continuous nature of the outcome value.\n",
    "\n",
    "Using ``sklearn`` for computation, the outcome of our linear regression predictions can be see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_X = training_data[:,0:-1]  # [dummy, score_diff, win_percentage, team_one_pos, team_two_pos]\n",
    "# train_X = training_data[:,[1]]  # [score_diff]\n",
    "train_Y = training_data[:,-1:]   # [resulting_score_diff]\n",
    "\n",
    "test_X = testing_data[:,0:-1]    # [dummy, score_diff, win_percentage, team_one_pos, team_two_pos]\n",
    "# test_X = testing_data[:,[1]]    # [score_diff]\n",
    "test_Y = testing_data[:,-1:]     # [resulting_score_diff]\n",
    "\n",
    "regr = sk.linear_model.LinearRegression()\n",
    "regr.fit(train_X, train_Y)\n",
    "\n",
    "pred_Y = regr.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_pred = []\n",
    "binary_actual = []\n",
    "correct_count = 0\n",
    "\n",
    "for val in pred_Y:\n",
    "    if val > 0:\n",
    "        binary_pred.append(1)\n",
    "    else:\n",
    "        binary_pred.append(0)\n",
    "        \n",
    "accuracy_rating = \"\"\n",
    "\n",
    "for indx, val in enumerate(binary_pred, 0):\n",
    "    correct_outcome_check = (np.sign(pred_Y[indx]) == np.sign(test_Y[indx]))\n",
    "    \n",
    "    if (abs(pred_Y[indx] - test_Y[indx]) == 0):\n",
    "        accuracy_rating = \"Spot On! ✅\"\n",
    "    elif (abs(pred_Y[indx] - test_Y[indx]) < 5) and (np.sign(pred_Y[indx]) == np.sign(test_Y[indx])):\n",
    "        accuracy_rating = \"Good ✅\"\n",
    "    elif (abs(pred_Y[indx] - test_Y[indx]) < 20) and (np.sign(pred_Y[indx]) == np.sign(test_Y[indx])):\n",
    "        accuracy_rating = \"Close ✅\"\n",
    "    elif (np.sign(pred_Y[indx]) == np.sign(test_Y[indx])):\n",
    "        accuracy_rating = \"Correct, but score need improvement ✅\"\n",
    "    elif (np.sign(pred_Y[indx]) != np.sign(test_Y[indx])):\n",
    "        accuracy_rating = \"Wrong ❌\"\n",
    "\n",
    "    print(wc_matches[indx]['name'] + \" vs. \" + wc_matches[indx]['opp_name'] + \":       Predicted: \" + str(pred_Y[indx]) + \"  |  Actual: \"+ str(test_Y[indx]) + \"    \" + accuracy_rating+\"\\n\")\n",
    "    if correct_outcome_check:\n",
    "        correct_count += 1\n",
    "        \n",
    "accuracy_rate = correct_count / len(binary_pred)\n",
    "\n",
    "accuracy_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By classifying the victorious team using the predicted score difference, our model managed to classify 91.11% of the World Cup games correctly. Additionally, the score differences that our model predicted are mostly within 20 points of the actual result.\n",
    "\n",
    "Though some of the predictions are off, we will look further into these games below in our conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Using a dataset containing the previous match stats of the 20 qualifying teams, the 2019 Rugby World Cup could have been predicted with a high percentage before it had even begun. Gaining insight into the details such as team rank, World Cup appearances, furthest stage reached, etc. we were able to produce extremely accurate predictions in the mining process of this project.\n",
    "\n",
    "Some of the incorrect predictions that incurred in our linear regression model were a result of how unpredictable occurences usually happen in reality. With the typhoon hitting Japan during the recent World Cup, the cancelled games may have skewed the results. This problem could not be countered, unless we were to look into weather data and storm patterns (which would be unnecessarily complex for this project). On the other hand, there are some incorrect predictions that might have been correctible upon gathering further information.\n",
    "\n",
    "With Japan winning all of their group stage games and making it into the quarterfinals, this unbelievable series of events could have been better predicted had we taken location into account as a contributing factor in the performance of a team. In most sports, a team playing in their home city/country can dramatically improve their performance due to less travel time and increased fan support.\n",
    "\n",
    "To further improve the results of our work, being more tedious towards outside information (such as home advantage) should allow our model to further improve its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
